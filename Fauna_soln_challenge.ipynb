{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanujsaini05/Solution-Challenge/blob/main/Fauna_soln_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-FK7Dne1Vl5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqkpCL0u1nsl"
      },
      "outputs": [],
      "source": [
        "from helper_functions import confusion_matrix,plot_loss_curves,create_tensorboard_callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new95vkB2DEx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkMYo7S92HxE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsMAHBYF2Mlo"
      },
      "outputs": [],
      "source": [
        "train_dir='/content/drive/MyDrive/Animalin/Train'\n",
        "test_dir='/content/drive/MyDrive/Animalin/Test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNE4UWEy2Oe7"
      },
      "outputs": [],
      "source": [
        "datagen=ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcm9DV1C2Rok",
        "outputId": "c6bd733e-31e8-45f8-f19a-2baf4ae28429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5891 images belonging to 9 classes.\n",
            "Found 461 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data=datagen.flow_from_directory(train_dir,target_size = (224, 224),\n",
        "    shuffle = True,\n",
        "    batch_size=32)\n",
        "\n",
        "test_data=datagen.flow_from_directory(test_dir,target_size=(224,224),shuffle=True,batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4joCncsnH0tn",
        "outputId": "bf843f2d-ced7-41a3-a502-c1e33decdd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'American Bully': 0, 'Buffalo': 1, 'Cat': 2, 'Cow': 3, 'German Shepherd': 4, 'Golden Retriever': 5, 'Labrador': 6, 'Pug': 7, 'Rottweiler': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14FmToGo2cE8"
      },
      "outputs": [],
      "source": [
        "Early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1,patience=3)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('model_checkpoints/final_one/cp_3.ckpt',save_best_only=True,monitor='val_loss',)\n",
        "\n",
        "Reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=0.2,min_lr=1e-7,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Z4fjwv2giP",
        "outputId": "2a23eb0f-fe22-46dc-b333-7cd07a70c690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_resnet= tf.keras.applications.ResNet50V2(include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2fGdXDS2mpP",
        "outputId": "1046d6a2-293c-4b00-9fde-e2d910cd314b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "i=0\n",
        "for layer in base_resnet.layers:\n",
        "  #print(f\"layer_name = {layer.name}  and number is {i}\")\n",
        "  if i>51 or i==0:\n",
        "    layer.trainable=False\n",
        "  i+=1\n",
        "for layer in base_resnet.layers:\n",
        "  print(layer.trainable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD95qcld2oXQ"
      },
      "outputs": [],
      "source": [
        "model_resnet = tf.keras.Sequential()\n",
        "model_resnet.add(base_resnet)\n",
        "model_resnet.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model_resnet.add(tf.keras.layers.Dense(9, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHhD-_rP2tIz"
      },
      "outputs": [],
      "source": [
        "model_resnet.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQKJVgfOzjDn",
        "outputId": "8dd5bc12-e06d-4c85-eb62-286846b52c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, None, None, 2048   23564800  \n",
            "                             )                                   \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9)                 18441     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23583241 (89.96 MB)\n",
            "Trainable params: 622729 (2.38 MB)\n",
            "Non-trainable params: 22960512 (87.59 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_resnet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHL2797H2vpE",
        "outputId": "e751e985-0439-487a-8a1e-7f911da659d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 1734s 9s/step - loss: 1.1904 - accuracy: 0.5867 - val_loss: 0.7944 - val_accuracy: 0.7137 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 530s 3s/step - loss: 0.4325 - accuracy: 0.8503 - val_loss: 0.6440 - val_accuracy: 0.7852 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 545s 3s/step - loss: 0.3082 - accuracy: 0.8929 - val_loss: 0.4765 - val_accuracy: 0.8395 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 542s 3s/step - loss: 0.2095 - accuracy: 0.9255 - val_loss: 0.3794 - val_accuracy: 0.8698 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9150\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "185/185 [==============================] - 519s 3s/step - loss: 0.2518 - accuracy: 0.9150 - val_loss: 0.3918 - val_accuracy: 0.8568 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 539s 3s/step - loss: 0.0955 - accuracy: 0.9705 - val_loss: 0.2522 - val_accuracy: 0.9067 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9869\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "185/185 [==============================] - 524s 3s/step - loss: 0.0537 - accuracy: 0.9869 - val_loss: 0.2625 - val_accuracy: 0.9132 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9929\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "185/185 [==============================] - 509s 3s/step - loss: 0.0418 - accuracy: 0.9929 - val_loss: 0.2573 - val_accuracy: 0.9176 - lr: 1.0000e-05\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9939\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "185/185 [==============================] - 510s 3s/step - loss: 0.0396 - accuracy: 0.9939 - val_loss: 0.2557 - val_accuracy: 0.9197 - lr: 1.0000e-06\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ],
      "source": [
        "hist_model_resnet=model_resnet.fit(train_data,validation_data=test_data,epochs=50,batch_size=32,verbose=1,callbacks=[Early_stopping,Reduce_lr,model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXvVHSpD3mpd"
      },
      "outputs": [],
      "source": [
        "from helper_functions import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.io.decode_image(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "load_and_prep_image(filename='1.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQMNN7tLAyae",
        "outputId": "6c987be1-fef1-4cc6-8d6a-b1532311184b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
              "array([[[0.4065989 , 0.43902186, 0.28096864],\n",
              "        [0.40436485, 0.46140268, 0.2290735 ],\n",
              "        [0.37457982, 0.42948177, 0.22163865],\n",
              "        ...,\n",
              "        [0.88235295, 0.88235295, 0.8901961 ],\n",
              "        [0.88235295, 0.88235295, 0.8901961 ],\n",
              "        [0.88235295, 0.88235295, 0.8901961 ]],\n",
              "\n",
              "       [[0.72935295, 0.7397521 , 0.70492506],\n",
              "        [0.42139295, 0.47664502, 0.2645302 ],\n",
              "        [0.3465336 , 0.40143555, 0.19359243],\n",
              "        ...,\n",
              "        [0.88235295, 0.88235295, 0.8901961 ],\n",
              "        [0.88235295, 0.88235295, 0.8901961 ],\n",
              "        [0.88692784, 0.88692784, 0.894771  ]],\n",
              "\n",
              "       [[0.7382784 , 0.7455263 , 0.7337347 ],\n",
              "        [0.41095936, 0.4662115 , 0.25009438],\n",
              "        [0.3395952 , 0.3944972 , 0.18665403],\n",
              "        ...,\n",
              "        [0.884944  , 0.884944  , 0.89278716],\n",
              "        [0.8862745 , 0.8862745 , 0.89411765],\n",
              "        [0.8862745 , 0.8862745 , 0.89411765]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.6967621 , 0.61440915, 0.53989935],\n",
              "        [0.6496632 , 0.5673103 , 0.49280047],\n",
              "        [0.59198755, 0.51416963, 0.44169632],\n",
              "        ...,\n",
              "        [0.5669448 , 0.4610742 , 0.40420556],\n",
              "        [0.50411683, 0.39431286, 0.3394109 ],\n",
              "        [0.50329137, 0.39348742, 0.33858547]],\n",
              "\n",
              "       [[0.6335663 , 0.5771239 , 0.53244615],\n",
              "        [0.63326377, 0.56267554, 0.5140762 ],\n",
              "        [0.60819346, 0.53760517, 0.4890059 ],\n",
              "        ...,\n",
              "        [0.49393207, 0.3880497 , 0.32138303],\n",
              "        [0.49411765, 0.39215687, 0.3254902 ],\n",
              "        [0.49471316, 0.39275238, 0.32608572]],\n",
              "\n",
              "       [[0.56442535, 0.5105739 , 0.4752798 ],\n",
              "        [0.5958564 , 0.5276261 , 0.48528296],\n",
              "        [0.5991598 , 0.5285715 , 0.4815127 ],\n",
              "        ...,\n",
              "        [0.49527374, 0.38939136, 0.3227247 ],\n",
              "        [0.512675  , 0.41071418, 0.34404752],\n",
              "        [0.5060419 , 0.4040811 , 0.33741444]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVSGSBgq4EIz"
      },
      "outputs": [],
      "source": [
        "\n",
        "pred_probs = model_resnet.predict(test_data, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6rHyIVR4LGN"
      },
      "outputs": [],
      "source": [
        "pred_classes = pred_probs.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBx4ICMy3miK"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_true=y_labels,y_pred=pred_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e1mZi6F3me6"
      },
      "outputs": [],
      "source": [
        "model_resnet.save(\"/content/drive/MyDrive/Animalin/Train/one.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDZ4W2_x3mZk"
      },
      "outputs": [],
      "source": [
        "!mkdir -p saved_model\n",
        "model_resnet.save('/content/drive/MyDrive/Animalin/Train/one.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGIn7zyk3mVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a13c9a-7bd5-4bc3-cce5-ce02602fa7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model_resnet.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Animalin/Train/one.keras')"
      ],
      "metadata": {
        "id": "n1mJBDXa3Dhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7pwfFI-3DDr",
        "outputId": "ff75f069-bfa8-497b-d548-7aa36d327a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, None, None, 2048   23564800  \n",
            "                             )                                   \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9)                 18441     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23583241 (89.96 MB)\n",
            "Trainable params: 622729 (2.38 MB)\n",
            "Non-trainable params: 22960512 (87.59 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpvClCCrG932",
        "outputId": "2bf4607f-d1fd-461a-e67b-87b46b661395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 18s 1s/step - loss: 0.2463 - accuracy: 0.9024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24625317752361298, 0.9023861289024353]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=new_model.predict(tf.expand_dims(load_and_prep_image(\"/content/drive/MyDrive/Animalin/Train/Labrador/aug_0_1004.jpg\"),axis=0)).argmax()\n",
        "a=[\"American Bully\",'Buffalo',\"Cat\",\"Cow\",\"German Shephard\",\"Golden Retriever\",\"Labrador\",\"Pug\",\"Rottweiler\"]\n",
        "print(f\"prediction is {a[prediction]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLIZm3dUI7bJ",
        "outputId": "51741134-f496-42ae-eaa2-1947f13287e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "prediction is Labrador\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1H4wPcAnCWTOrqQwuckR9OmOQU-fBoxWi",
      "authorship_tag": "ABX9TyMdPRH88jb4QYU+hxndhFBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}